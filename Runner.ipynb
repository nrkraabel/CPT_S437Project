{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from DataHandler import *\n",
    "from model import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_by_id, images_by_coordinates, path_to_coordinates = load_dataN5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49421"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path_to_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data for the dataset\n",
    "image_paths = []\n",
    "coordinates = []\n",
    "for image_path, coord in path_to_coordinates.items():\n",
    "    image_paths.append(image_path)\n",
    "    coordinates.append(coord)\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = ImageGPSDataset(image_paths=image_paths, coordinates=coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "#custom Collate was needed when pulling from onedrive \n",
    "batch_size = 64\n",
    "def custom_collate(batch):\n",
    "    # Filter out all None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    \n",
    "    # Check if the batch is empty after filtering\n",
    "    if len(batch) == 0:\n",
    "        return None, None\n",
    "\n",
    "    return default_collate(batch)\n",
    "\n",
    "# Update DataLoader initialization\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageGPSModelV3().to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Load the model done if training in stages \n",
    "# checkpoint = torch.load(\"image_gps_model.pth\")\n",
    "# model = ImageGPSModelV3().cuda()  \n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  \n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 109.61436410860722, Validation Loss: 11.166921538691367\n",
      "Epoch [2/20], Train Loss: 42.05371894651246, Validation Loss: 10.292149546838576\n",
      "Epoch [3/20], Train Loss: 39.50049320085149, Validation Loss: 5.090897663177983\n",
      "Epoch [4/20], Train Loss: 36.715514389828186, Validation Loss: 29.62695807180097\n",
      "Epoch [5/20], Train Loss: 36.652943700648436, Validation Loss: 7.019998562720514\n",
      "Epoch [6/20], Train Loss: 35.13193722141599, Validation Loss: 4.716100829647433\n",
      "Epoch [7/20], Train Loss: 34.21224067280593, Validation Loss: 4.058991296829716\n",
      "Epoch [8/20], Train Loss: 33.768168958645425, Validation Loss: 11.386006958253923\n",
      "Epoch [9/20], Train Loss: 32.520445360720736, Validation Loss: 3.5395016685608893\n",
      "Epoch [10/20], Train Loss: 32.63605586301933, Validation Loss: 10.379664150361092\n",
      "Epoch [11/20], Train Loss: 31.426953800287833, Validation Loss: 5.680720190848073\n",
      "Epoch [12/20], Train Loss: 31.561928252186203, Validation Loss: 7.271219468885852\n",
      "Epoch [13/20], Train Loss: 31.523544434976422, Validation Loss: 4.825675212183306\n",
      "Epoch [14/20], Train Loss: 30.890000043949264, Validation Loss: 3.0670754701860488\n",
      "Epoch [15/20], Train Loss: 30.109216921537826, Validation Loss: 4.623197875484344\n",
      "Epoch [16/20], Train Loss: 29.82523094411807, Validation Loss: 3.000368712025304\n",
      "Epoch [17/20], Train Loss: 29.580014336842165, Validation Loss: 3.277052797809724\n",
      "Epoch [18/20], Train Loss: 28.749929486740754, Validation Loss: 6.495843315124512\n",
      "Epoch [19/20], Train Loss: 28.323491935976886, Validation Loss: 13.119696537140877\n",
      "Epoch [20/20], Train Loss: 28.5642073378208, Validation Loss: 6.915385095534786\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Initialize the gradient scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "epochs = 20 # Number of epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        if batch is None or batch[0] is None or batch[1] is None:\n",
    "            # Skip the entire batch if it is None\n",
    "            continue\n",
    "\n",
    "        images, coords = batch\n",
    "        images = images.to(device)\n",
    "        coords = coords.to(device)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with automatic mixed precision done for optimization\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, coords)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            if batch is None or batch[0] is None or batch[1] is None:\n",
    "                # Skip the entire batch if it is None\n",
    "                continue\n",
    "\n",
    "            images, coords = batch\n",
    "            images = images.to(device)\n",
    "            coords = coords.to(device)\n",
    "\n",
    "            # Forward pass for validation\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = loss_function(outputs, coords)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {total_train_loss/len(train_loader)}, Validation Loss: {total_val_loss/len(val_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"image_gps_model.pth\"\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss_function,\n",
    "    'scaler_state_dict': scaler.state_dict(),  \n",
    "}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"image_gps_modellite.pth\"\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model defination \n",
    "# modelRes = ResnetGPSModel().to(device)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(modelRes.parameters(), lr=0.001)\n",
    "\n",
    "# Load the model done if training in stages \n",
    "checkpoint = torch.load(\"Resnet_model.pth\")\n",
    "modelRes = ResnetGPSModel().cuda()  \n",
    "modelRes.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.Adam(modelRes.parameters(), lr=0.001) \n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss : 85.98870776367187, Validation Loss: 11.794769226558625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "epochs = 1  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training Phase\n",
    "    modelRes.train()  \n",
    "    total_train_loss = 0\n",
    "\n",
    "    for images, coords in train_loader:\n",
    "        images = images.to(device)\n",
    "        coords = coords.to(device)\n",
    "\n",
    "        # # Debuging\n",
    "        # assert not torch.isnan(images).any(), \"NaN values in training images\"\n",
    "        # assert not torch.isnan(coords).any(), \"NaN values in training coords\"\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = modelRes(images)  # Forward pass\n",
    "\n",
    "        # # Debuging\n",
    "        # assert not torch.isnan(outputs).any(), \"NaN values in model output during training\"\n",
    "\n",
    "        loss = loss_function(outputs, coords)  # Compute loss\n",
    "\n",
    "        # # Debuging\n",
    "        # assert not torch.isnan(loss).any(), \"NaN values in loss during training\"\n",
    "\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation Phase\n",
    "    modelRes.eval()  \n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for images, coords in val_loader:\n",
    "            images = images.to(device)\n",
    "            coords = coords.to(device)\n",
    "\n",
    "            # # Debuging\n",
    "            # assert not torch.isnan(images).any(), \"NaN values in validation images\"\n",
    "            # assert not torch.isnan(coords).any(), \"NaN values in validation coords\"\n",
    "\n",
    "            outputs = modelRes(images)  # Forward pass\n",
    "\n",
    "            # # Debuging\n",
    "            # assert not torch.isnan(outputs).any(), \"NaN values in model output during validation\"\n",
    "\n",
    "            loss = loss_function(outputs, coords)  # Compute loss\n",
    "\n",
    "            # #Debuging\n",
    "            # assert not torch.isnan(loss).any(), \"NaN values in loss during validation\"\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss : {avg_train_loss}, Validation Loss: {avg_val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model saving \n",
    "modelRes.to('cpu')\n",
    "model_path = \"Resnet_model.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': modelRes.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss_function,\n",
    "}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from DataHandler import *\n",
    "from model import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
