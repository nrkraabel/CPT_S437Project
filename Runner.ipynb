{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from DataHandler import *\n",
    "from model import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_by_id, images_by_coordinates, path_to_coordinates = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data for the dataset\n",
    "image_paths = []\n",
    "coordinates = []\n",
    "for image_path, coord in path_to_coordinates.items():\n",
    "    image_paths.append(image_path)\n",
    "    coordinates.append(coord)\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = ImageGPSDataset(image_paths=image_paths, coordinates=coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ImageGPSModelV3().to(device)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Load the model done if training in stages \n",
    "checkpoint = torch.load(\"image_gps_model.pth\")\n",
    "model = ImageGPSModelV3().cuda()  # Replace with your actual model class\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Replace with your actual optimizer\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 29.63516915130615, Validation Loss: 1.8841905802015275\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Initialize the gradient scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "epochs = 1 # Number of epochs\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for images, coords in train_loader:\n",
    "        images = images.to(device)\n",
    "        coords = coords.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with automatic mixed precision done for optimization\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, coords)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, coords in val_loader:\n",
    "            images = images.to(device)\n",
    "            coords = coords.to(device)\n",
    "\n",
    "            # Forward pass for validation\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = loss_function(outputs, coords)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {total_train_loss/len(train_loader)}, Validation Loss: {total_val_loss/len(val_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"image_gps_model.pth\"\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss_function,\n",
    "    'scaler_state_dict': scaler.state_dict(),  # If you're using GradScaler for mixed precision\n",
    "}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model defination \n",
    "# modelRes = ResnetGPSModel().to(device)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(modelRes.parameters(), lr=0.001)\n",
    "\n",
    "# Load the model done if training in stages \n",
    "checkpoint = torch.load(\"Resnet_model.pth\")\n",
    "modelRes = ResnetGPSModel().cuda()  # Replace with your actual model class\n",
    "modelRes.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.Adam(modelRes.parameters(), lr=0.001)  # Replace with your actual optimizer\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss : 85.98870776367187, Validation Loss: 11.794769226558625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "epochs = 1  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training Phase\n",
    "    modelRes.train()  \n",
    "    total_train_loss = 0\n",
    "\n",
    "    for images, coords in train_loader:\n",
    "        images = images.to(device)\n",
    "        coords = coords.to(device)\n",
    "\n",
    "        # # Debuging\n",
    "        # assert not torch.isnan(images).any(), \"NaN values in training images\"\n",
    "        # assert not torch.isnan(coords).any(), \"NaN values in training coords\"\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = modelRes(images)  # Forward pass\n",
    "\n",
    "        # # Debuging\n",
    "        # assert not torch.isnan(outputs).any(), \"NaN values in model output during training\"\n",
    "\n",
    "        loss = loss_function(outputs, coords)  # Compute loss\n",
    "\n",
    "        # # Debuging\n",
    "        # assert not torch.isnan(loss).any(), \"NaN values in loss during training\"\n",
    "\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation Phase\n",
    "    modelRes.eval()  \n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for images, coords in val_loader:\n",
    "            images = images.to(device)\n",
    "            coords = coords.to(device)\n",
    "\n",
    "            # # Debuging\n",
    "            # assert not torch.isnan(images).any(), \"NaN values in validation images\"\n",
    "            # assert not torch.isnan(coords).any(), \"NaN values in validation coords\"\n",
    "\n",
    "            outputs = modelRes(images)  # Forward pass\n",
    "\n",
    "            # # Debuging\n",
    "            # assert not torch.isnan(outputs).any(), \"NaN values in model output during validation\"\n",
    "\n",
    "            loss = loss_function(outputs, coords)  # Compute loss\n",
    "\n",
    "            # #Debuging\n",
    "            # assert not torch.isnan(loss).any(), \"NaN values in loss during validation\"\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss : {avg_train_loss}, Validation Loss: {avg_val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model saving \n",
    "modelRes.to('cpu')\n",
    "model_path = \"Resnet_model.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': modelRes.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss_function,\n",
    "}, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from DataHandler import *\n",
    "from model import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
